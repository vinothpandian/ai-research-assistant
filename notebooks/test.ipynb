{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T00:59:36.380834Z",
     "start_time": "2023-12-29T00:59:36.325392Z"
    }
   },
   "id": "404a3a774866cfb1",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-29T00:59:37.780847Z",
     "start_time": "2023-12-29T00:59:37.633220Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = httpx.get(\"https://api.semanticscholar.org/graph/v1/paper/search\", params=dict(\n",
    "    fields=\"paperId,title,abstract,url,authors,publicationDate\",\n",
    "    query=\"ui sketch dataset\"\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T00:59:39.029397Z",
     "start_time": "2023-12-29T00:59:38.500664Z"
    }
   },
   "id": "ad0097077684ccc9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'total': 3070,\n 'offset': 0,\n 'next': 10,\n 'data': [{'paperId': '1fef45786e707e6b9b8517b0403e596ecbdea6a5',\n   'url': 'https://www.semanticscholar.org/paper/1fef45786e707e6b9b8517b0403e596ecbdea6a5',\n   'title': 'Sketch-based manga retrieval using manga109 dataset',\n   'abstract': None,\n   'publicationDate': '2015-10-15',\n   'authors': [{'authorId': '46461083', 'name': 'Yusuke Matsui'},\n    {'authorId': '2111362155', 'name': 'Kota Ito'},\n    {'authorId': '27292760', 'name': 'Yuji Aramaki'},\n    {'authorId': '21340869', 'name': 'Azuma Fujimoto'},\n    {'authorId': '2113646541', 'name': 'Toru Ogawa'},\n    {'authorId': '145572097', 'name': 'T. Yamasaki'},\n    {'authorId': '1712839', 'name': 'K. Aizawa'}]},\n  {'paperId': '56f254877417f134bb670f3483560ace47b8f869',\n   'url': 'https://www.semanticscholar.org/paper/56f254877417f134bb670f3483560ace47b8f869',\n   'title': 'ARSketch: Sketch-Based User Interface for Augmented Reality Glasses',\n   'abstract': 'Hand gesture interaction is a key component in Augmented Reality (AR) / Mixed Reality (MR). Users usually interact with AR/MR devices, e.g., Microsoft HoloLens, etc., via hand gestures to express their intentions and the devices will recognize the gestures and respond accordingly to users. However, the use of such technique so far is limited to only a few less-expressive hand gestures, which, unfortunately, are insufficient or inadequate to input complex information. To tackle this problem, we introduce a sketch-based neural network-driven user interface for AR/MR glasses, called ARSketch, which enables drawing sketches freely in air to interact with the devices. ARSketch combines: (1) hand pose estimation that estimates the egocentric hand poses in an energy-efficient way, (2) sketch generation that generates sketches using key point positions of hand poses, and (3) sketch-photo retrieval that takes sketches as inputs to retrieve relevant photos. The evaluation results on our collected sketch dataset demonstrate the efficacy of ARSketch for user interaction.',\n   'publicationDate': '2020-10-12',\n   'authors': [{'authorId': '2156120066', 'name': 'Zhaohui Zhang'},\n    {'authorId': '2387872', 'name': 'Haichao Zhu'},\n    {'authorId': '2145948441', 'name': 'Qian Zhang'}]},\n  {'paperId': 'b3fb8047675e1dbdef800ce32abbfe1dccb42235',\n   'url': 'https://www.semanticscholar.org/paper/b3fb8047675e1dbdef800ce32abbfe1dccb42235',\n   'title': 'Generalisation and Sharing in Triplet Convnets for Sketch based Visual Search',\n   'abstract': 'We propose and evaluate several triplet CNN architectures for measuring the similarity between sketches and photographs, within the context of the sketch based image retrieval (SBIR) task. In contrast to recent fine-grained SBIR work, we study the ability of our networks to generalise across diverse object categories from limited training data, and explore in detail strategies for weight sharing, pre-processing, data augmentation and dimensionality reduction. We exceed the performance of pre-existing techniques on both the Flickr15k category level SBIR benchmark by $18\\\\%$, and the TU-Berlin SBIR benchmark by $\\\\sim10 \\\\mathcal{T}_b$, when trained on the 250 category TU-Berlin classification dataset augmented with 25k corresponding photographs harvested from the Internet.',\n   'publicationDate': '2016-11-16',\n   'authors': [{'authorId': '144655022', 'name': 'Tu Bui'},\n    {'authorId': '1502030036', 'name': 'Leo Sampaio Ferraz Ribeiro'},\n    {'authorId': '145202695', 'name': 'M. Ponti'},\n    {'authorId': '1680236', 'name': 'J. Collomosse'}]},\n  {'paperId': '8faa2f72699fe1dc35b643a711a02a15f6b65475',\n   'url': 'https://www.semanticscholar.org/paper/8faa2f72699fe1dc35b643a711a02a15f6b65475',\n   'title': 'Context-based sketch classification',\n   'abstract': 'We present a novel context-based sketch classification framework using relations extracted from scene images. Most of existing methods perform sketch classification by considering individually sketched objects and often fail to identify their correct categories, due to the highly abstract nature of sketches. For a sketched scene containing multiple objects, we propose to classify a sketched object by considering its surrounding context in the scene, which provides vital cues for alleviating its recognition ambiguity. We learn such context knowledge from a database of scene images by summarizing the inter-object relations therein, such as co-occurrence, relative positions and sizes. We show that the context information can be used for both incremental sketch classification and sketch co-classification. Our method outperforms a state-of-the-art single-object classification method, evaluated on a new dataset of sketched scenes.',\n   'publicationDate': '2018-08-17',\n   'authors': [{'authorId': '2108240464', 'name': 'Jianhui Zhang'},\n    {'authorId': '1820305', 'name': 'Yilan Chen'},\n    {'authorId': '104470106', 'name': 'Lei Li'},\n    {'authorId': '3169698', 'name': 'Hongbo Fu'},\n    {'authorId': '38705735', 'name': 'Chiew-Lan Tai'}]},\n  {'paperId': '6e8e239534b9fff48df3493bf112eb5d047dca26',\n   'url': 'https://www.semanticscholar.org/paper/6e8e239534b9fff48df3493bf112eb5d047dca26',\n   'title': 'Panoramic Image Generation: From 2-D Sketch to Spherical Image',\n   'abstract': 'The 360-degree video/image, also called an omnidirectional video/image or panoramic video/image, is very important in some emerging areas such as virtual reality (VR). Therefore, corresponding image generation algorithms are urgently needed. However, existing image generation models mainly focus on 2-D images and do not consider the spherical structures of panoramic images. In this article, we propose a panoramic image generation method based on spherical convolution and generative adversarial networks, called spherical generative adversarial networks (SGANs). We adopt the sketch map as the input, which is a concise geometric structure representation of the panoramic image, e.g., comprising approximately 7% of the pixels for a 583 Ã— 1163 image. Through adversarial learning, a realistic-looking, plausible and high-fidelity spherical image can be obtained from the sparse sketch map. In particular, we build a dataset of the sketch maps using a visual computation-based sketching model. Then, by optimizing SGANs with GAN loss, feature matching loss and perceptual loss, realistic textures and details are recovered gradually. On one hand, it is an improvement using the sparse sketch map as input rather than the denser input, e.g., the features of the textures and colors. On the other hand, spherical convolution helps to remedy space-varying distortions of the planar projection. We conduct extensive experiments on some public panoramic image datasets and compare them with state-of-the-art techniques to validate the superior performance of the proposed approach.',\n   'publicationDate': '2020-01-01',\n   'authors': [{'authorId': '1866977', 'name': 'Yiping Duan'},\n    {'authorId': '2118643437', 'name': 'Chaoyi Han'},\n    {'authorId': '144978572', 'name': 'Xiaoming Tao'},\n    {'authorId': '79791439', 'name': 'Bingrui Geng'},\n    {'authorId': '2111745087', 'name': 'Yunfei Du'},\n    {'authorId': '1694070', 'name': 'Jianhua Lu'}]},\n  {'paperId': 'f8ea16db66904733f8e5dda96cf73f524b13dac2',\n   'url': 'https://www.semanticscholar.org/paper/f8ea16db66904733f8e5dda96cf73f524b13dac2',\n   'title': 'Deep Manifold Alignment for Mid-Grain Sketch Based Image Retrieval',\n   'abstract': None,\n   'publicationDate': '2018-12-02',\n   'authors': [{'authorId': '144655022', 'name': 'Tu Bui'},\n    {'authorId': '144282279', 'name': 'Leonardo Ribeiro'},\n    {'authorId': '145202695', 'name': 'M. Ponti'},\n    {'authorId': '1680236', 'name': 'J. Collomosse'}]},\n  {'paperId': 'c61236874e13da131cbc66fbb47bc33f282eb899',\n   'url': 'https://www.semanticscholar.org/paper/c61236874e13da131cbc66fbb47bc33f282eb899',\n   'title': 'SPFusionNet: Sketch Segmentation Using Multi-modal Data Fusion',\n   'abstract': 'The sketch segmentation problem remains largely unsolved because conventional methods are greatly challenged by the highly abstract appearances of freehand sketches and their numerous shape variations. In this work, we tackle such challenges by exploiting different modes of sketch data in a unified framework. Specifically, we propose a deep neural network SPFusionNet to capture the characteristic of sketch by fusing from its image and point set modes. The image modal component SketchNet learns hierarchically abstract ro-bust features and utilizes multi-level representations to produce pixel-wise feature maps, while the point set-modal component SPointNet captures local and global contexts of the sampled point set to produce point-wise feature maps. Then our framework aggregates these feature maps by a fusion network component to generate the sketch segmentation result. The extensive experimental evaluation and comparison with peer methods on our large SketchSeg dataset verify the effectiveness of the proposed framework.',\n   'publicationDate': '2019-07-01',\n   'authors': [{'authorId': '2148957338', 'name': 'Fei Wang'},\n    {'authorId': '1779766', 'name': 'Shujin Lin'},\n    {'authorId': '1721715', 'name': 'Hefeng Wu'},\n    {'authorId': '1596827002', 'name': 'Hanhui Li'},\n    {'authorId': '2108693798', 'name': 'Ruomei Wang'},\n    {'authorId': '144361019', 'name': 'Xiaonan Luo'},\n    {'authorId': '1706670', 'name': 'Xiangjian He'}]},\n  {'paperId': '528c39bd8ecd77ff8c66b559880f5f8e86725830',\n   'url': 'https://www.semanticscholar.org/paper/528c39bd8ecd77ff8c66b559880f5f8e86725830',\n   'title': 'Retrieving Aerial Scene Images with Learned Deep Image-Sketch Features',\n   'abstract': None,\n   'publicationDate': '2017-07-14',\n   'authors': [{'authorId': '32046173', 'name': 'Tianbi Jiang'},\n    {'authorId': '39943835', 'name': 'Gui-Song Xia'},\n    {'authorId': '2457942', 'name': 'Qikai Lu'},\n    {'authorId': '2117226132', 'name': 'Weiming Shen'}]},\n  {'paperId': '36657aaf5e657b891b5289286235ba54b80c5b84',\n   'url': 'https://www.semanticscholar.org/paper/36657aaf5e657b891b5289286235ba54b80c5b84',\n   'title': 'Markov random fields for sketch based video retrieval',\n   'abstract': 'We describe a new system for searching video databases using free-hand sketched queries. Our query sketches depict both object appearance and motion, and are annotated with keywords that indicate the semantic category of each object. We parse space-time volumes from video to form graph representation, which we match to sketches under a Markov Random Field (MRF) optimization. The MRF energy function is used to rank videos for relevance and contains unary, pairwise and higher-order potentials that reflect the colour, shape, motion and type of sketched objects. We evaluate performance over a dataset of 500 sports footage clips.',\n   'publicationDate': '2013-04-16',\n   'authors': [{'authorId': '2067784668', 'name': 'Rui Hu'},\n    {'authorId': '49280934', 'name': 'Stuart James'},\n    {'authorId': '46958572', 'name': 'T. Wang'},\n    {'authorId': '1680236', 'name': 'J. Collomosse'}]},\n  {'paperId': '673bd00caccb10a7e91f35d9d5f4ded1c6bcad95',\n   'url': 'https://www.semanticscholar.org/paper/673bd00caccb10a7e91f35d9d5f4ded1c6bcad95',\n   'title': 'Sketch-based aerial image retrieval',\n   'abstract': 'Notwithstanding aerial image retrieval is an important and obligatory task, existing retrieval systems lose their efficiency when there is no available aerial image used as the exemplar query. In this paper, we take free-hand sketches into consideration and address the problem of sketch-based aerial image retrieval. This is an extremely challenging task due to the complex surface structures and huge variations of resolutions of aerial images, and few works have been devoted to it. For the first time to our knowledge, we propose a framework to bridge the gap between sketches and aerial images. Specifically, an aerial sketch-image dataset is first collected. Sketches and aerial images are augmented to varied levels of details and used to train a multi-scale deep hierarchical model. The fully-connected layers of the deep model are used as cross-domain features, and the similarity between aerial images and sketches is measured by the Euclidean distance. Experiments on several public aerial image datasets demonstrate the efficiency and superiority of the proposed method.',\n   'publicationDate': '2017-09-01',\n   'authors': [{'authorId': '32046173', 'name': 'Tianbi Jiang'},\n    {'authorId': '39943835', 'name': 'Gui-Song Xia'},\n    {'authorId': '2457942', 'name': 'Qikai Lu'}]}]}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.json()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T00:59:39.541093Z",
     "start_time": "2023-12-29T00:59:39.522530Z"
    }
   },
   "id": "5d2cb6acc6307e7c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SemanticScholarArticlesList(root=[SemanticScholarArticle(paperId='1fef45786e707e6b9b8517b0403e596ecbdea6a5', title='Sketch-based manga retrieval using manga109 dataset', abstract='', url='https://www.semanticscholar.org/paper/1fef45786e707e6b9b8517b0403e596ecbdea6a5', authors=[Author(name='Yusuke Matsui'), Author(name='Kota Ito'), Author(name='Yuji Aramaki'), Author(name='Azuma Fujimoto'), Author(name='Toru Ogawa'), Author(name='T. Yamasaki'), Author(name='K. Aizawa')], publicationDate='2015-10-15'), SemanticScholarArticle(paperId='56f254877417f134bb670f3483560ace47b8f869', title='ARSketch: Sketch-Based User Interface for Augmented Reality Glasses', abstract='Hand gesture interaction is a key component in Augmented Reality (AR) / Mixed Reality (MR). Users usually interact with AR/MR devices, e.g., Microsoft HoloLens, etc., via hand gestures to express their intentions and the devices will recognize the gestures and respond accordingly to users. However, the use of such technique so far is limited to only a few less-expressive hand gestures, which, unfortunately, are insufficient or inadequate to input complex information. To tackle this problem, we introduce a sketch-based neural network-driven user interface for AR/MR glasses, called ARSketch, which enables drawing sketches freely in air to interact with the devices. ARSketch combines: (1) hand pose estimation that estimates the egocentric hand poses in an energy-efficient way, (2) sketch generation that generates sketches using key point positions of hand poses, and (3) sketch-photo retrieval that takes sketches as inputs to retrieve relevant photos. The evaluation results on our collected sketch dataset demonstrate the efficacy of ARSketch for user interaction.', url='https://www.semanticscholar.org/paper/56f254877417f134bb670f3483560ace47b8f869', authors=[Author(name='Zhaohui Zhang'), Author(name='Haichao Zhu'), Author(name='Qian Zhang')], publicationDate='2020-10-12'), SemanticScholarArticle(paperId='b3fb8047675e1dbdef800ce32abbfe1dccb42235', title='Generalisation and Sharing in Triplet Convnets for Sketch based Visual Search', abstract='We propose and evaluate several triplet CNN architectures for measuring the similarity between sketches and photographs, within the context of the sketch based image retrieval (SBIR) task. In contrast to recent fine-grained SBIR work, we study the ability of our networks to generalise across diverse object categories from limited training data, and explore in detail strategies for weight sharing, pre-processing, data augmentation and dimensionality reduction. We exceed the performance of pre-existing techniques on both the Flickr15k category level SBIR benchmark by $18\\\\%$, and the TU-Berlin SBIR benchmark by $\\\\sim10 \\\\mathcal{T}_b$, when trained on the 250 category TU-Berlin classification dataset augmented with 25k corresponding photographs harvested from the Internet.', url='https://www.semanticscholar.org/paper/b3fb8047675e1dbdef800ce32abbfe1dccb42235', authors=[Author(name='Tu Bui'), Author(name='Leo Sampaio Ferraz Ribeiro'), Author(name='M. Ponti'), Author(name='J. Collomosse')], publicationDate='2016-11-16'), SemanticScholarArticle(paperId='8faa2f72699fe1dc35b643a711a02a15f6b65475', title='Context-based sketch classification', abstract='We present a novel context-based sketch classification framework using relations extracted from scene images. Most of existing methods perform sketch classification by considering individually sketched objects and often fail to identify their correct categories, due to the highly abstract nature of sketches. For a sketched scene containing multiple objects, we propose to classify a sketched object by considering its surrounding context in the scene, which provides vital cues for alleviating its recognition ambiguity. We learn such context knowledge from a database of scene images by summarizing the inter-object relations therein, such as co-occurrence, relative positions and sizes. We show that the context information can be used for both incremental sketch classification and sketch co-classification. Our method outperforms a state-of-the-art single-object classification method, evaluated on a new dataset of sketched scenes.', url='https://www.semanticscholar.org/paper/8faa2f72699fe1dc35b643a711a02a15f6b65475', authors=[Author(name='Jianhui Zhang'), Author(name='Yilan Chen'), Author(name='Lei Li'), Author(name='Hongbo Fu'), Author(name='Chiew-Lan Tai')], publicationDate='2018-08-17'), SemanticScholarArticle(paperId='6e8e239534b9fff48df3493bf112eb5d047dca26', title='Panoramic Image Generation: From 2-D Sketch to Spherical Image', abstract='The 360-degree video/image, also called an omnidirectional video/image or panoramic video/image, is very important in some emerging areas such as virtual reality (VR). Therefore, corresponding image generation algorithms are urgently needed. However, existing image generation models mainly focus on 2-D images and do not consider the spherical structures of panoramic images. In this article, we propose a panoramic image generation method based on spherical convolution and generative adversarial networks, called spherical generative adversarial networks (SGANs). We adopt the sketch map as the input, which is a concise geometric structure representation of the panoramic image, e.g., comprising approximately 7% of the pixels for a 583 Ã— 1163 image. Through adversarial learning, a realistic-looking, plausible and high-fidelity spherical image can be obtained from the sparse sketch map. In particular, we build a dataset of the sketch maps using a visual computation-based sketching model. Then, by optimizing SGANs with GAN loss, feature matching loss and perceptual loss, realistic textures and details are recovered gradually. On one hand, it is an improvement using the sparse sketch map as input rather than the denser input, e.g., the features of the textures and colors. On the other hand, spherical convolution helps to remedy space-varying distortions of the planar projection. We conduct extensive experiments on some public panoramic image datasets and compare them with state-of-the-art techniques to validate the superior performance of the proposed approach.', url='https://www.semanticscholar.org/paper/6e8e239534b9fff48df3493bf112eb5d047dca26', authors=[Author(name='Yiping Duan'), Author(name='Chaoyi Han'), Author(name='Xiaoming Tao'), Author(name='Bingrui Geng'), Author(name='Yunfei Du'), Author(name='Jianhua Lu')], publicationDate='2020-01-01'), SemanticScholarArticle(paperId='f8ea16db66904733f8e5dda96cf73f524b13dac2', title='Deep Manifold Alignment for Mid-Grain Sketch Based Image Retrieval', abstract='', url='https://www.semanticscholar.org/paper/f8ea16db66904733f8e5dda96cf73f524b13dac2', authors=[Author(name='Tu Bui'), Author(name='Leonardo Ribeiro'), Author(name='M. Ponti'), Author(name='J. Collomosse')], publicationDate='2018-12-02'), SemanticScholarArticle(paperId='c61236874e13da131cbc66fbb47bc33f282eb899', title='SPFusionNet: Sketch Segmentation Using Multi-modal Data Fusion', abstract='The sketch segmentation problem remains largely unsolved because conventional methods are greatly challenged by the highly abstract appearances of freehand sketches and their numerous shape variations. In this work, we tackle such challenges by exploiting different modes of sketch data in a unified framework. Specifically, we propose a deep neural network SPFusionNet to capture the characteristic of sketch by fusing from its image and point set modes. The image modal component SketchNet learns hierarchically abstract ro-bust features and utilizes multi-level representations to produce pixel-wise feature maps, while the point set-modal component SPointNet captures local and global contexts of the sampled point set to produce point-wise feature maps. Then our framework aggregates these feature maps by a fusion network component to generate the sketch segmentation result. The extensive experimental evaluation and comparison with peer methods on our large SketchSeg dataset verify the effectiveness of the proposed framework.', url='https://www.semanticscholar.org/paper/c61236874e13da131cbc66fbb47bc33f282eb899', authors=[Author(name='Fei Wang'), Author(name='Shujin Lin'), Author(name='Hefeng Wu'), Author(name='Hanhui Li'), Author(name='Ruomei Wang'), Author(name='Xiaonan Luo'), Author(name='Xiangjian He')], publicationDate='2019-07-01'), SemanticScholarArticle(paperId='528c39bd8ecd77ff8c66b559880f5f8e86725830', title='Retrieving Aerial Scene Images with Learned Deep Image-Sketch Features', abstract='', url='https://www.semanticscholar.org/paper/528c39bd8ecd77ff8c66b559880f5f8e86725830', authors=[Author(name='Tianbi Jiang'), Author(name='Gui-Song Xia'), Author(name='Qikai Lu'), Author(name='Weiming Shen')], publicationDate='2017-07-14'), SemanticScholarArticle(paperId='36657aaf5e657b891b5289286235ba54b80c5b84', title='Markov random fields for sketch based video retrieval', abstract='We describe a new system for searching video databases using free-hand sketched queries. Our query sketches depict both object appearance and motion, and are annotated with keywords that indicate the semantic category of each object. We parse space-time volumes from video to form graph representation, which we match to sketches under a Markov Random Field (MRF) optimization. The MRF energy function is used to rank videos for relevance and contains unary, pairwise and higher-order potentials that reflect the colour, shape, motion and type of sketched objects. We evaluate performance over a dataset of 500 sports footage clips.', url='https://www.semanticscholar.org/paper/36657aaf5e657b891b5289286235ba54b80c5b84', authors=[Author(name='Rui Hu'), Author(name='Stuart James'), Author(name='T. Wang'), Author(name='J. Collomosse')], publicationDate='2013-04-16'), SemanticScholarArticle(paperId='673bd00caccb10a7e91f35d9d5f4ded1c6bcad95', title='Sketch-based aerial image retrieval', abstract='Notwithstanding aerial image retrieval is an important and obligatory task, existing retrieval systems lose their efficiency when there is no available aerial image used as the exemplar query. In this paper, we take free-hand sketches into consideration and address the problem of sketch-based aerial image retrieval. This is an extremely challenging task due to the complex surface structures and huge variations of resolutions of aerial images, and few works have been devoted to it. For the first time to our knowledge, we propose a framework to bridge the gap between sketches and aerial images. Specifically, an aerial sketch-image dataset is first collected. Sketches and aerial images are augmented to varied levels of details and used to train a multi-scale deep hierarchical model. The fully-connected layers of the deep model are used as cross-domain features, and the similarity between aerial images and sketches is measured by the Euclidean distance. Experiments on several public aerial image datasets demonstrate the efficiency and superiority of the proposed method.', url='https://www.semanticscholar.org/paper/673bd00caccb10a7e91f35d9d5f4ded1c6bcad95', authors=[Author(name='Tianbi Jiang'), Author(name='Gui-Song Xia'), Author(name='Qikai Lu')], publicationDate='2017-09-01')])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.schema.semantic_scholar import SemanticScholarArticlesList\n",
    "\n",
    "SemanticScholarArticlesList.model_validate(data.json()['data'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:04:38.043529Z",
     "start_time": "2023-12-29T01:04:37.932696Z"
    }
   },
   "id": "5490dfc5f891a3fb",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "352c386058fc2859"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = httpx.post(\"http://localhost:11434/api/embeddings\", json={\"model\": \"orca-mini\", \"prompt\": \"test\", \"stream\": False}).json()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "348cddbcbb3e4e51",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(data['embedding'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4e3b8734fcd28",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a56b0803ccc3d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = httpx.post(\"http://localhost:11434/api/embeddings\", json={\"model\": \"dolphin-phi\", \"prompt\": \"test\", \"stream\": False}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c3232dc797e43",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(len(data['embedding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f05fdbe304161a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = httpx.get(\"http://localhost:8000/arxiv/search/?q=test&start=0&limit=10\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed683eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup existing data\n",
    "response = httpx.get(\"http://localhost:8000/articles/\").json()\n",
    "\n",
    "for item in response['items']:\n",
    "    httpx.delete(f\"http://localhost:8000/articles/?article_id={item['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a876702353d77a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for item in data['items']:\n",
    "    article = dict(\n",
    "        arxiv_id=item['id'],\n",
    "        title=item['title'],\n",
    "        abstract=item['summary'],\n",
    "        link=item['link'],\n",
    "        published=item['published'],\n",
    "        authors=[author['name'] for author in item['authors']],\n",
    "    )\n",
    "\n",
    "    httpx.post(\"http://localhost:8000/articles/\", json=article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762b4e0df1864f2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = {\n",
    "#     \"model\": \"llama2\",\n",
    "#     \"prompt\": \"Context: The effective electron-electron interaction in the electron gas depends on both the density and spin local field factors. Variational Diagrammatic Quantum Monte Carlo calculations of the spin local field factor are reported and used to quantitatively present the full spin-dependent, electron-electron interaction. Together with the charge local field factor from previous Diffusion Quantum Monte Carlo calculations, we obtain the complete form of the effective electron-electron interaction in the uniform three-dimensional electron gas. Very simple quadratic formulas are presented for the local field factors that quantitatively produce all of the response functions of the electron gas at metallic densities. Exchange and correlation become increasingly important at low densities. At the compressibility divergence at rs = 5.25, both the direct (screened Coulomb) term and the charge-dependent exchange term in the electron-electron interaction at q=0 are separately divergent. However, due to large cancellations, their difference is finite, well behaved, and much smaller than either term separately. As a result, the spin contribution to the electron-electron interaction becomes an important factor. The static electron-electron interaction is repulsive as a function of density but is less repulsive for electrons with parallel spins. The effect of allowing a deformable, rather than rigid, positive background is shown to be as quantitatively important as exchange and correlation. As a simple concrete example, the electron-electron interaction is calculated using the measured bulk modulus of the alkali metals with a linear phonon dispersion. The net electron-electron interaction in lithium is attractive for wave vectors $0-2k_F$, which suggests superconductivity, and is mostly repulsive for the other alkali metals.\\n\\nThe effect of the electron-electron cusp on the convergence of configuration interaction (CI) wave functions is examined. By analogy with the pseudopotential approach for electron-ion interactions, an effective electron-electron interaction is developed which closely reproduces the scattering of the Coulomb interaction but is smooth and finite at zero electron-electron separation. The exact many-electron wave function for this smooth effective interaction has no cusp at zero electron-electron separation. We perform CI and quantum Monte Carlo calculations for He and Be atoms, both with the Coulomb electron-electron interaction and with the smooth effective electron-electron interaction. We find that convergence of the CI expansion of the wave function for the smooth electron-electron interaction is not significantly improved compared with that for the divergent Coulomb interaction for energy differences on the order of 1 mHartree. This shows that, contrary to popular belief, description of the electron-electron cusp is not a limiting factor, to within chemical accuracy, for CI calculations.\\n\\nBased on the metastable electron-pair energy band in a two-dimensional (2D) periodic potential obtained previously by Hai and Castelano [J. Phys.: Condens. Matter 26, 115502 (2014)], we present in this work a Hamiltonian of many electrons consisting of single electrons and electron pairs in the 2D system. The electron-pair states are metastable of energies higher than those of the single-electron states at low electron density. We assume two different scenarios for the single-electron band. When it is considered as the lowest conduction band of a crystal, we compare the obtained Hamiltonian with the phenomenological model Hamiltonian of a boson-fermion mixture proposed by Friedberg and Lee [Phys. Rev. B 40, 6745 (1989)]. Single-electron-electron-pair and electron-pair-electron-pair interaction terms appear in our Hamiltonian and the interaction potentials can be determined from the electron-electron Coulomb interactions. When we consider the single-electron band as the highest valence band of a crystal, we show that holes in this valence band are important for stabilization of the electron-pair states in the system.\\n\\nStarting from the shell structure in atoms and the significant correlation within electron pairs, we distinguish the exchange-correlation effects between two electrons of opposite spins occupying the same orbital from the average correlation among many electrons in a crystal. In the periodic potential of the crystal with lattice constant larger than the effective Bohr radius of the valence electrons, these correlated electron pairs can form a metastable energy band above the corresponding single-electron band separated by an energy gap. In order to determine if these metastable electron pairs can be stabilized, we calculate the many-electron exchange-correlation renormalization and the polaron correction to the two-band system with single electrons and electron pairs. We find that the electron-phonon interaction is essential to counterbalance the Coulomb repulsion and to stabilize the electron pairs. The interplay of the electron-electron and electron-phonon interactions, manifested in the exchange-correlation energies, polaron effects, and screening, is responsible for the formation of electron pairs (bipolarons) that are located on the Fermi surface of the single-electron band.\\n\\nWe probe the strength of electron-electron interactions using magnetoconductivity measurements of two-dimensional non-degenerate electrons on liquid helium at 1.22 K. Our data extend to electron densities that are two orders of magnitude smaller than previously reported. We span both the independent-electron regime where the data are qualitatively described by the self-consistent Born approximation (SCBA), and the strongly-interacting electron regime. At finite fields we observe a crossover from SCBA to Drude theory as a function of electron density.\\n\\n    Question: explain electron ion interaction?\\n\\n    Answer: \",\n",
    "#     \"stream\": True\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e136ec3b5f4a35",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# httpx.post(\"http://localhost:11434/api/generate\", json=data, timeout=None).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6122e6d1b93adc4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_prompt = \"Answer the question based on the context given below. The answer should only contain information that\\n    is present in the context. The answer should not contain any information that is not present in the context. The\\n    answer should be in your own words and should not be a copy of the context. The answer should be in English and\\n    should be grammatically correct. The answer should be in complete sentences and should be in markdown format.\\n\\n    ###\\n    Context: The effect of the electron-electron cusp on the convergence of configuration interaction (CI) wave functions is examined. By analogy with the pseudopotential approach for electron-ion interactions, an effective electron-electron interaction is developed which closely reproduces the scattering of the Coulomb interaction but is smooth and finite at zero electron-electron separation. The exact many-electron wave function for this smooth effective interaction has no cusp at zero electron-electron separation. We perform CI and quantum Monte Carlo calculations for He and Be atoms, both with the Coulomb electron-electron interaction and with the smooth effective electron-electron interaction. We find that convergence of the CI expansion of the wave function for the smooth electron-electron interaction is not significantly improved compared with that for the divergent Coulomb interaction for energy differences on the order of 1 mHartree. This shows that, contrary to popular belief, description of the electron-electron cusp is not a limiting factor, to within chemical accuracy, for CI calculations.\\n\\nElectron temperature anisotropies and electron beams are nonthermal features of the observed nonequilibrium electron velocity distributions in the solar wind. In collision-poor plasmas these nonequilibrium distributions are expected to be regulated by kinetic instabilities through wave-particle interactions. This study considers electron instabilities driven by the interplay of core electron temperature anisotropies and the electron beam, and firstly gives a comprehensive analysis of instabilities in arbitrary directions to the background magnetic field. It clarifies the dominant parameter regime (e.g., parallel core electron plasma beta $\\\\beta_{\\\\mathrm{ec\\\\parallel}}$, core electron temperature anisotropy $A_{\\\\mathrm{ec}}\\\\equiv T_{\\\\mathrm{ec\\\\perp}}/T_{\\\\mathrm{ec\\\\parallel}}$, and electron beam velocity $V_{\\\\mathrm{eb}}$) for each kind of electron instability (e.g., the electron beam-driven electron acoustic/magnetoacoustic instability, the electron beam-driven whistler instability, the electromagnetic electron cyclotron instability, the electron mirror instability, the electron firehose instability, and the ordinary-mode instability). It finds that the electron beam can destabilize electron acoustic/magnetoacoustic waves in the low-$\\\\beta_{\\\\mathrm{ec\\\\parallel}}$ regime, and whistler waves in the medium- and large-$\\\\beta_{\\\\mathrm{ec\\\\parallel}}$ regime. It also finds that a new oblique fast-magnetosonic/whistler instability is driven by the electron beam with $V_{\\\\mathrm{eb}}\\\\gtrsim7V_{\\\\mathrm{A}}$ in a regime where $\\\\beta_{\\\\mathrm{ec\\\\parallel}}\\\\sim0.1-2$ and $A_{\\\\mathrm{ec}}<1$. Moreover, this study presents electromagnetic responses of each kind of electron instability. These results provide a comprehensive overview for electron instability constraints on core electron temperature anisotropies and electron beams in the solar wind.\\n\\nWe probe the strength of electron-electron interactions using magnetoconductivity measurements of two-dimensional non-degenerate electrons on liquid helium at 1.22 K. Our data extend to electron densities that are two orders of magnitude smaller than previously reported. We span both the independent-electron regime where the data are qualitatively described by the self-consistent Born approximation (SCBA), and the strongly-interacting electron regime. At finite fields we observe a crossover from SCBA to Drude theory as a function of electron density.\\n\\nIt is assumed that, in the primordial plasma, at the temperatures above the mass of electron, fermions are in the neutral state being the superposition of particle and antiparticle. There exists neutral proton-electron symmetry. Proton-electron equilibrium is defined by the proton-electron mass difference. At the temperature equal to the mass of electron, pairs of neutral electrons annihilate into photons, and pairs of neutral protons and electrons survive as protons and electrons.\\n\\nWe calculate the thermal conductivity of electrons produced by electron-electron Coulomb scattering in a strongly degenerate electron gas taking into account the Landau damping of transverse plasmons. The Landau damping strongly reduces this conductivity in the domain of ultrarelativistic electrons at temperatures below the electron plasma temperature. In the inner crust of a neutron star at temperatures T < 1e7 K this thermal conductivity completely dominates over the electron conductivity due to electron-ion (electron-phonon) scattering and becomes competitive with the the electron conductivity due to scattering of electrons by impurity ions.\\n\\n    Question: explain electron ion interaction?\\n\\n    Answer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac574dfd8b4abd8e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "async def get_stream():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        data = {'model': \"dolphin-phi\", 'prompt': question_prompt, 'stream': True}\n",
    "        request = client.build_request(\"POST\", \"http://localhost:11434/api/generate\", json=data, timeout=None)\n",
    "        r = await client.send(request, stream=True)\n",
    "        async for chunk in r.aiter_text():\n",
    "            with contextlib.suppress(JSONDecodeError):\n",
    "                json_chunk = json.loads(chunk)\n",
    "                print(json_chunk['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d140f2b066140d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "await get_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11726df21f4716e5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "from json import JSONDecodeError\n",
    "completed = False\n",
    "\n",
    "async def get_stream():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        request = client.build_request(\"GET\", \"http://localhost:8000/articles/search/?question=explain%20electron%20ion%20interaction&score_threshold=0.1&with_answer=true\", timeout=None)\n",
    "        r = await client.send(request, stream=True)\n",
    "        async for chunk in r.aiter_text():\n",
    "            with contextlib.suppress(JSONDecodeError):\n",
    "                json_chunk = json.loads(chunk)\n",
    "                print(json_chunk)\n",
    "                \n",
    "        print(\"done\")\n",
    "        completed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edba57ed8b6036",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "await get_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
