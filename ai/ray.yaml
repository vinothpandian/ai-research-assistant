proxy_location: EveryNode

http_options:
  host: 0.0.0.0
  port: 9000

logging_config:
  encoding: TEXT
  log_level: INFO
  logs_dir: null
  enable_access_log: true

applications:
  - name: embedding-generator
    route_prefix: /embedding
    import_path: ai.embedding:embedding_app
    runtime_env:
      pip:
        - sentence-transformers==2.2.2
        - ray[serve]==2.9.0

    deployments:
      - name: EmbeddingGenerator
        max_concurrent_queries: 8
        autoscaling_config:
          target_num_ongoing_requests_per_replica: 2
          min_replicas: 8
          max_replicas: 16
        ray_actor_options:
          num_cpus: 1.0
          num_gpus: 0.0

  - name: question-answering
    route_prefix: /answer
    import_path: ai.question_answering:qa_app
    runtime_env:
      pip:
        - sentence-transformers==2.2.2
        - ray[serve]==2.9.0

    deployments:
      - name: QuestionAnswering
        autoscaling_config:
          target_num_ongoing_requests_per_replica: 1
          min_replicas: 0
          max_replicas: 1
        ray_actor_options:
          num_cpus: 1.0
          num_gpus: 0.0

  - name: summarizer
    route_prefix: /summarize
    import_path: ai.summarizer:summarizer_app
    runtime_env:
      pip:
        - sentence-transformers==2.2.2
        - ray[serve]==2.9.0

    deployments:
      - name: Summarizer
        autoscaling_config:
          target_num_ongoing_requests_per_replica: 1
          min_replicas: 0
          max_replicas: 1
        ray_actor_options:
          num_cpus: 1.0
          num_gpus: 0.0
